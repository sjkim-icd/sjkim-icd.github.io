---
layout: post
title:  "성적에 영향을 미치는 요인 분석"
summary: "Analytics"
author: KSJ
date: '2021-03-12 09:41:00 +0900'
categories: Analytics
---

## **분석주제 :학습 성공/실패 요소**

----------

연구데이터인 학습관련 데이터를 활용하여 DATA HANDLING, EDA, MODELING을 진행해 보려고 합니다.
해당 데이터는 캐글의 다음 URL에서 살펴볼 수 있습니다.
https://www.kaggle.com/aljarah/xAPI-Edu-Data

데이터의 경우, xAPI-Edu-Data 데이터셋인 xAPI-Edu-Data.csv를 사용합니다.

## Contents

1. [데이터 분석 문제 정의](#1.-데이터-분석-문제-정의)
2. [데이터 EDA](3.-데이터EDA)
3. [데이터 핸들링](#2.데이터-핸들링)
4. [모델링](#4.-모델링)
5. [마무리](#5.-마무리)

변수의 의미는 다음과 같습니다.<br>

    - 각 파일의 컬럼은 아래와 같습니다.
    gender: 학생의 성별 (M: 남성, F: 여성)
    NationaliTy: 학생의 국적
    PlaceofBirth: 학생이 태어난 국가
    StageID: 학생이 다니는 학교 (초,중,고)
    GradeID: 학생이 속한 성적 등급
    SectionID: 학생이 속한 반 이름
    Topic: 수강한 과목
    Semester: 수강한 학기 (1학기/2학기)
    Relation: 주 보호자와 학생의 관계
    raisedhands: 학생이 수업 중 손을 든 횟수
    VisITedResources: 학생이 과목 공지를 확인한 횟수
    Discussion: 학생이 토론 그룹에 참여한 횟수
    ParentAnsweringSurvey: 부모가 학교 설문에 참여했는지 여부
    ParentschoolSatisfaction: 부모가 학교에 만족했는지 여부
    StudentAbscenceDays: 학생의 결석 횟수 (7회 이상/미만)
    Class: 학생의 성적 등급 (L: 낮음, M: 보통, H: 높음)


​    
- 데이터 출처: https://www.kaggle.com/aljarah/xAPI-Edu-Data

## 해당 분석에서 배울 수 있는 것
    - 연구용 데이터의 이해
    - 데이터 시각화
    - Scikit-learn 기반 모델 학습 방법 습득
    - Logistic Regression, XGBoost 모델링 방법
    - 학습된 모델의 평가 방법 및 시각화 방법

---

# 1. **데이터 분석 문제 정의**



해당 분석의 경우, class(학생의 성적등급)가 target 값입니다. 낮음/보통/높음으로 구분할 수 있습니다.

## 데이터셋 준비


```python
import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import seaborn as sns
```

###  Colab Notebook에 Kaggle API 세팅하기



```python
import os
```


```python
# os.environ을 이용하여 Kaggle API Username, Key 세팅하기

os.environ['KAGGLE_USERNAME']='sojeongkimdesign'

os.environ['KAGGLE_KEY']='bd7482b7426c6d140c3e8ef3b602b202'
```

### 데이터 다운로드 및 압축 해제하기



```python
# Linux 명령어로 Kaggle API를 이용하여 데이터셋 다운로드하기 (!kaggle ~)

# Linux 명령어로 압축 해제하기



!kaggle -h

!kaggle datasets download -d aljarah/xAPI-Edu-Data

!unzip '*.zip'
```

    usage: kaggle [-h] [-v] {competitions,c,datasets,d,kernels,k,config} ...
    
    optional arguments:
      -h, --help            show this help message and exit
      -v, --version         show program's version number and exit
    
    commands:
      {competitions,c,datasets,d,kernels,k,config}
                            Use one of:
                            competitions {list, files, download, submit, submissions, leaderboard}
                            datasets {list, files, download, create, version, init, metadata, status}
                            config {view, set, unset}
        competitions        Commands related to Kaggle competitions
        datasets            Commands related to Kaggle datasets
        kernels             Commands related to Kaggle kernels
        config              Configuration settings
    Downloading xAPI-Edu-Data.zip to /content
      0% 0.00/5.54k [00:00<?, ?B/s]
    100% 5.54k/5.54k [00:00<00:00, 7.91MB/s]
    Archive:  xAPI-Edu-Data.zip
      inflating: xAPI-Edu-Data.csv       


### Pandas 라이브러리로 csv파일 읽어들이기



```python
ls
```

    [0m[01;34msample_data[0m/  xAPI-Edu-Data.csv  xAPI-Edu-Data.zip



```python
# pd.read_csv()로 csv파일 읽어들이기

df = pd.read_csv('xAPI-Edu-Data.csv')
```

# **2. 데이터 EDA**


##2-1. 데이터프레임의 각 컬럼 분석



```python
# DataFrame에서 제공하는 메소드를 이용하여 컬럼 분석하기 (head(), info(), describe())



df.head()

print(df.head().to_markdown())
```

    |    | gender   | NationalITy   | PlaceofBirth   | StageID    | GradeID   | SectionID   | Topic   | Semester   | Relation   |   raisedhands |   VisITedResources |   AnnouncementsView |   Discussion | ParentAnsweringSurvey   | ParentschoolSatisfaction   | StudentAbsenceDays   | Class   |
    |---:|:---------|:--------------|:---------------|:-----------|:----------|:------------|:--------|:-----------|:-----------|--------------:|-------------------:|--------------------:|-------------:|:------------------------|:---------------------------|:---------------------|:--------|
    |  0 | M        | KW            | KuwaIT         | lowerlevel | G-04      | A           | IT      | F          | Father     |            15 |                 16 |                   2 |           20 | Yes                     | Good                       | Under-7              | M       |
    |  1 | M        | KW            | KuwaIT         | lowerlevel | G-04      | A           | IT      | F          | Father     |            20 |                 20 |                   3 |           25 | Yes                     | Good                       | Under-7              | M       |
    |  2 | M        | KW            | KuwaIT         | lowerlevel | G-04      | A           | IT      | F          | Father     |            10 |                  7 |                   0 |           30 | No                      | Bad                        | Above-7              | L       |
    |  3 | M        | KW            | KuwaIT         | lowerlevel | G-04      | A           | IT      | F          | Father     |            30 |                 25 |                   5 |           35 | No                      | Bad                        | Above-7              | L       |
    |  4 | M        | KW            | KuwaIT         | lowerlevel | G-04      | A           | IT      | F          | Father     |            40 |                 50 |                  12 |           50 | No                      | Bad                        | Above-7              | M       |



```python
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 480 entries, 0 to 479
    Data columns (total 17 columns):
     #   Column                    Non-Null Count  Dtype 
    ---  ------                    --------------  ----- 
     0   gender                    480 non-null    object
     1   NationalITy               480 non-null    object
     2   PlaceofBirth              480 non-null    object
     3   StageID                   480 non-null    object
     4   GradeID                   480 non-null    object
     5   SectionID                 480 non-null    object
     6   Topic                     480 non-null    object
     7   Semester                  480 non-null    object
     8   Relation                  480 non-null    object
     9   raisedhands               480 non-null    int64 
     10  VisITedResources          480 non-null    int64 
     11  AnnouncementsView         480 non-null    int64 
     12  Discussion                480 non-null    int64 
     13  ParentAnsweringSurvey     480 non-null    object
     14  ParentschoolSatisfaction  480 non-null    object
     15  StudentAbsenceDays        480 non-null    object
     16  Class                     480 non-null    object
    dtypes: int64(4), object(13)
    memory usage: 63.9+ KB


연구용 데이터이므로 비워져있는 데이터가 없는 깔끔한 모습을 볼 수 있습니다. 수치형 데이터가 정수형으로 되어있는걸 볼 수 있는데 범주형은 string으로 들어가 있습니다. info에는 object로 뜨는데 객체라는 의미이고

정확한 class는 파악하지 못한 것으로 보이네요.

몇가지 변수의 class를 확인해보겠습니다.


```python
df.columns
```




    Index(['gender', 'NationalITy', 'PlaceofBirth', 'StageID', 'GradeID',
           'SectionID', 'Topic', 'Semester', 'Relation', 'raisedhands',
           'VisITedResources', 'AnnouncementsView', 'Discussion',
           'ParentAnsweringSurvey', 'ParentschoolSatisfaction',
           'StudentAbsenceDays', 'Class'],
          dtype='object')




```python
df['gender'].value_counts()
```




    M    305
    F    175
    Name: gender, dtype: int64




```python
df['NationalITy'].value_counts()
```




    KW             179
    Jordan         172
    Palestine       28
    Iraq            22
    lebanon         17
    Tunis           12
    SaudiArabia     11
    Egypt            9
    Syria            7
    USA              6
    Iran             6
    Lybia            6
    Morocco          4
    venzuela         1
    Name: NationalITy, dtype: int64




```python
df.describe()

print(df.describe().to_markdown())
```

    |       |   raisedhands |   VisITedResources |   AnnouncementsView |   Discussion |
    |:------|--------------:|-------------------:|--------------------:|-------------:|
    | count |      480      |           480      |            480      |     480      |
    | mean  |       46.775  |            54.7979 |             37.9188 |      43.2833 |
    | std   |       30.7792 |            33.08   |             26.6112 |      27.6377 |
    | min   |        0      |             0      |              0      |       1      |
    | 25%   |       15.75   |            20      |             14      |      20      |
    | 50%   |       50      |            65      |             33      |      39      |
    | 75%   |       75      |            84      |             58      |      70      |
    | max   |      100      |            99      |             98      |      99      |


수치형 데이터들이 어떤 특성을 가지고 있는지를 볼 수 있습니다.

##2-2 수치형 데이터 EDA



### seaborn의 histplot, jointplot, pairplot을 이용해 히스토그램 그리기

#### histplot

- raisedhands




```python
sns.histplot(x='raisedhands',data=df,hue = 'Class', hue_order=('L','M','H'),kde =True)

plt.show()
```


![png](학습요소_files/학습요소_24_0.png)


뚜렷하게 쌍봉 형태로 나타나는 것을 볼 수 있습니다.

L의 경우, raisehands가 낮은 쪽에 몰려 있습니다.

M의 경우, 쌍봉에 모두 속해있고,

H의 경우  raisehands의 높은 쪽에 몰려 있습니다.



즉 손을 많이 든 학생이 등급이 높을 것이라는 것을 알 수 있습니다. 상관성이 있다는 거죠.

- VisITedResources: 학생이 과목 공지를 확인한 횟수


```python
sns.histplot(x='VisITedResources',data=df,hue = 'Class', hue_order=('L','M','H'),kde =True)

plt.show()
```


![png](학습요소_files/학습요소_27_0.png)


손드는 학생과 비슷한 양상을 보이지만,

M의 높은 쪽으로 몰려있는 것을 볼 수 있습니다. <br>

즉, 학생이 과목 공지를 확인한 횟수가 손을 드는 행위보다

조금 더 성적에 영향을 더 주는 것으로 추정할 수 있습니다. <br>



- AnnouncementsView


```python
sns.histplot(x='AnnouncementsView',data=df,hue = 'Class', hue_order=('L','M','H'),kde =True)

plt.show()
```


![png](학습요소_files/학습요소_29_0.png)


L인 학생은 수업 외적인 알람을 확인하지 않는 경우가 많고,H,M의 학생은 일반 공지확인에는 큰 연관성은 없어보입니다. 즉 H,M학생도 일반 공지에는 관심없는 경우도 꽤 있다는 걸 알 수 있습니다.



- Discussion




```python
sns.histplot(x='Discussion',data=df,hue = 'Class', hue_order=('L','M','H'),kde =True)

plt.show()
```


![png](학습요소_files/학습요소_31_0.png)


Discussion의 경우 경향성이 잘 보이지는 않습니다.

L,M의 경우 디스커션이 낮은쪽에 몰려있고

H는 쌍봉 형태로 나타나고 있습니다.

#### jointplot


```python
sns.jointplot(x='VisITedResources',y='raisedhands',data=df, hue ='Class', hue_order=('L','M','H'))

plt.show()
```


![png](학습요소_files/학습요소_34_0.png)


L과 M은 구분이 잘 되는 것이 보이네요.



#### pariplot

모든 경우의 조인트 플랏을 한번에 출력해주는 plot


```python
sns.pairplot(df, hue ='Class', hue_order=['L','M','H'])

plt.show()
```


![png](학습요소_files/학습요소_36_0.png)


pairplot을 했을때 scatter plot이 일자로 나타나면 나타날수록 두 가지가 상관성이 높다는 것인데

펼쳐져있는 것은 상관성이 낮다는 의미입니다.

클래스가 잘 갈라지는 분포로 나온다는 것은 

서로 다른 두 가지를 동시에 보는 것이 유용하다는 의미입니다.

## 2-3. 범주형 데이터 EDA
#### Countplot



```python
sns.countplot(x= 'Class', data = df,order=['L','M','H'])

plt.show()
```


![png](학습요소_files/학습요소_39_0.png)



```python
sns.countplot(x= 'gender', data = df,hue = 'Class', hue_order=['L','M','H'])

plt.show()
```


![png](학습요소_files/학습요소_40_0.png)


남학생은 성적이 낮은 쪽에 분포

비율로 보면 여학생이 성적이 좋은편이네요.


```python
df.columns
```




    Index(['gender', 'NationalITy', 'PlaceofBirth', 'StageID', 'GradeID',
           'SectionID', 'Topic', 'Semester', 'Relation', 'raisedhands',
           'VisITedResources', 'AnnouncementsView', 'Discussion',
           'ParentAnsweringSurvey', 'ParentschoolSatisfaction',
           'StudentAbsenceDays', 'Class'],
          dtype='object')




```python
sns.countplot(x= 'NationalITy', data = df,hue = 'Class', hue_order=['L','M','H'])

plt.xticks(rotation=90)

plt.show()
```


![png](학습요소_files/학습요소_43_0.png)


성적이 좋지 않은 쪽에 몰려있는 나라는 쿠웨이트, 좋은 쪽은 미국/레바논/요르단/이라크를 볼 수 있겠네요.



데이터 간의 상관성을 보는거지 dependency를 보는게 아니니 주의해야 합니다.


```python
sns.countplot(x= 'ParentAnsweringSurvey', data = df,hue = 'Class', hue_order=['L','M','H'])

plt.show()
```


![png](학습요소_files/학습요소_45_0.png)


부모가 설문조사에 응한 경우, L인 경우가 많지 않네요. 부모의 관심이 학생 성적에 상관성이 있다는 거죠.


```python
sns.countplot(x= 'ParentschoolSatisfaction', data = df,hue = 'Class', hue_order=['L','M','H'])

plt.show()
```


![png](학습요소_files/학습요소_47_0.png)


만족한 경우, 성적이 좋게 나오는데요. 

성적이 좋았기 때문에 만족이 높았을 수도 있으니 성적을 알기 전에 한 설문인지 여부에 따라 분석을 할 때 빼거나 넣을 수 있겠습니다.


```python
sns.countplot(x= 'Topic', data = df,hue = 'Class', hue_order=['L','M','H'])

plt.xticks(rotation=90)

plt.show()
```


![png](학습요소_files/학습요소_49_0.png)


IT선택 학생은 L이 많네요.

bio가 H입니다.

학생들이 어떤 과목을 어려워하는지를 알 수 있겠죠.

### 범주형 컬럼 -> 수치로 변경

 


```python
# L, M, H를 숫자로 바꾸어 표현
# DF의 map() 메소드 사용

df['Class_value'] = df['Class'].map(dict(L=-1,M=0,H=1)) # class_value라는 파생변수 생성
print(df.head().to_markdown)
```

    <bound method DataFrame.to_markdown of   gender NationalITy PlaceofBirth  ... StudentAbsenceDays Class Class_value
    0      M          KW       KuwaIT  ...            Under-7     M           0
    1      M          KW       KuwaIT  ...            Under-7     M           0
    2      M          KW       KuwaIT  ...            Above-7     L          -1
    3      M          KW       KuwaIT  ...            Above-7     L          -1
    4      M          KW       KuwaIT  ...            Above-7     M           0
    
    [5 rows x 18 columns]>


Class_value 컬럼으로 시각화


```python
gb_gender =  df.groupby('gender').mean()['Class_value']
gb_gender

plt.bar(gb_gender.index,gb_gender)
plt.show()
```


![png](학습요소_files/학습요소_54_0.png)


남학생은 L이 많아 음수로 나타남


```python
gb =  df.groupby('Topic').mean()['Class_value'].sort_values()

gb



plt.barh(gb.index,gb)

plt.show()
```


![png](%ED%95%99%EC%8A%B5_files/%ED%95%99%EC%8A%B5_56_0.png)


IT/Spanish는 성적이 낮고

Bio가 성적이 높음


```python
gb =  df.groupby('StudentAbsenceDays').mean()['Class_value'].sort_values()

gb



plt.barh(gb.index,gb)

plt.show()
```


![png](학습요소_files/학습요소_58_0.png)


결석이 7이하면 0.4로 성적이 좋은 편

남녀 차이보다 크다는 걸 알 수 있습니다.

# 3. 데이터 전처리



```python
df.columns
```




    Index(['gender', 'NationalITy', 'PlaceofBirth', 'StageID', 'GradeID',
           'SectionID', 'Topic', 'Semester', 'Relation', 'raisedhands',
           'VisITedResources', 'AnnouncementsView', 'Discussion',
           'ParentAnsweringSurvey', 'ParentschoolSatisfaction',
           'StudentAbsenceDays', 'Class', 'Class_value'],
          dtype='object')




```python
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 480 entries, 0 to 479
    Data columns (total 18 columns):
     #   Column                    Non-Null Count  Dtype 
    ---  ------                    --------------  ----- 
     0   gender                    480 non-null    object
     1   NationalITy               480 non-null    object
     2   PlaceofBirth              480 non-null    object
     3   StageID                   480 non-null    object
     4   GradeID                   480 non-null    object
     5   SectionID                 480 non-null    object
     6   Topic                     480 non-null    object
     7   Semester                  480 non-null    object
     8   Relation                  480 non-null    object
     9   raisedhands               480 non-null    int64 
     10  VisITedResources          480 non-null    int64 
     11  AnnouncementsView         480 non-null    int64 
     12  Discussion                480 non-null    int64 
     13  ParentAnsweringSurvey     480 non-null    object
     14  ParentschoolSatisfaction  480 non-null    object
     15  StudentAbsenceDays        480 non-null    object
     16  Class                     480 non-null    object
     17  Class_value               480 non-null    int64 
    dtypes: int64(5), object(13)
    memory usage: 67.6+ KB


#### get_dummies() 사용
 one-hot 벡터로 변환할 때 사용



```python
# 범주형 변수 넣기



X = pd.get_dummies(df.drop(['ParentschoolSatisfaction', 'Class', 'Class_value'], axis=1), #drop 안하면 나머지는 수치형으로 가지고옴/컬럼에서 드랍

                   columns=['gender', 'NationalITy', 'PlaceofBirth',

                            'StageID', 'GradeID','SectionID', 'Topic',

                            'Semester', 'Relation', 'ParentAnsweringSurvey',

                            'StudentAbsenceDays'],

                   drop_first=True) #Multicollinearity를 피하기 위해 drop_first=True로 설정

                     #'ParentschoolSatisfaction', 데이터 스퀴즈 가능성

y = df['Class']

X
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>raisedhands</th>
      <th>VisITedResources</th>
      <th>AnnouncementsView</th>
      <th>Discussion</th>
      <th>gender_M</th>
      <th>NationalITy_Iran</th>
      <th>NationalITy_Iraq</th>
      <th>NationalITy_Jordan</th>
      <th>NationalITy_KW</th>
      <th>NationalITy_Lybia</th>
      <th>NationalITy_Morocco</th>
      <th>NationalITy_Palestine</th>
      <th>NationalITy_SaudiArabia</th>
      <th>NationalITy_Syria</th>
      <th>NationalITy_Tunis</th>
      <th>NationalITy_USA</th>
      <th>NationalITy_lebanon</th>
      <th>NationalITy_venzuela</th>
      <th>PlaceofBirth_Iran</th>
      <th>PlaceofBirth_Iraq</th>
      <th>PlaceofBirth_Jordan</th>
      <th>PlaceofBirth_KuwaIT</th>
      <th>PlaceofBirth_Lybia</th>
      <th>PlaceofBirth_Morocco</th>
      <th>PlaceofBirth_Palestine</th>
      <th>PlaceofBirth_SaudiArabia</th>
      <th>PlaceofBirth_Syria</th>
      <th>PlaceofBirth_Tunis</th>
      <th>PlaceofBirth_USA</th>
      <th>PlaceofBirth_lebanon</th>
      <th>PlaceofBirth_venzuela</th>
      <th>StageID_MiddleSchool</th>
      <th>StageID_lowerlevel</th>
      <th>GradeID_G-04</th>
      <th>GradeID_G-05</th>
      <th>GradeID_G-06</th>
      <th>GradeID_G-07</th>
      <th>GradeID_G-08</th>
      <th>GradeID_G-09</th>
      <th>GradeID_G-10</th>
      <th>GradeID_G-11</th>
      <th>GradeID_G-12</th>
      <th>SectionID_B</th>
      <th>SectionID_C</th>
      <th>Topic_Biology</th>
      <th>Topic_Chemistry</th>
      <th>Topic_English</th>
      <th>Topic_French</th>
      <th>Topic_Geology</th>
      <th>Topic_History</th>
      <th>Topic_IT</th>
      <th>Topic_Math</th>
      <th>Topic_Quran</th>
      <th>Topic_Science</th>
      <th>Topic_Spanish</th>
      <th>Semester_S</th>
      <th>Relation_Mum</th>
      <th>ParentAnsweringSurvey_Yes</th>
      <th>StudentAbsenceDays_Under-7</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>15</td>
      <td>16</td>
      <td>2</td>
      <td>20</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>20</td>
      <td>20</td>
      <td>3</td>
      <td>25</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10</td>
      <td>7</td>
      <td>0</td>
      <td>30</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>30</td>
      <td>25</td>
      <td>5</td>
      <td>35</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>40</td>
      <td>50</td>
      <td>12</td>
      <td>50</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>475</th>
      <td>5</td>
      <td>4</td>
      <td>5</td>
      <td>8</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>476</th>
      <td>50</td>
      <td>77</td>
      <td>14</td>
      <td>28</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>477</th>
      <td>55</td>
      <td>74</td>
      <td>25</td>
      <td>29</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>478</th>
      <td>30</td>
      <td>17</td>
      <td>14</td>
      <td>57</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>479</th>
      <td>35</td>
      <td>14</td>
      <td>23</td>
      <td>62</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>480 rows × 59 columns</p>
</div>



## 학습데이터와 테스트데이터 분리


# 4. 모델링


```python
from sklearn.model_selection import train_test_split
```


```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)
```

##  Classification 모델 학습


###  Logistic Regression 모델 생성/학습하기


```python
from sklearn.linear_model import LogisticRegression
```


```python
# LogisticRegression 모델 생성/학습

model_lr = LogisticRegression(max_iter = 10000) #max_iteration에 대해 늘려라고 나옴 Increase the number of iterations (max_iter)

model_lr.fit(X_train, y_train)
```




    LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                       intercept_scaling=1, l1_ratio=None, max_iter=10000,
                       multi_class='auto', n_jobs=None, penalty='l2',
                       random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                       warm_start=False)



### regression 모델 학습 결과 평가
- classification_report() 결과 출력하기



```python
from sklearn.metrics import classification_report
```


```python
# Predict를 수행하고 classification_report() 결과 출력하기

pred = model_lr.predict(X_test)

print(classification_report(y_test,pred))
```

                  precision    recall  f1-score   support
    
               H       0.74      0.74      0.74        50
               L       0.85      0.70      0.77        33
               M       0.66      0.72      0.69        61
    
        accuracy                           0.72       144
       macro avg       0.75      0.72      0.73       144
    weighted avg       0.73      0.72      0.72       144


​    

### XGBoost 모델 생성/학습


```python
from xgboost import XGBClassifier
```


```python
model_xgb = XGBClassifier()

model_xgb.fit(X_train, y_train)
```




    XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
                  colsample_bynode=1, colsample_bytree=1, gamma=0,
                  learning_rate=0.1, max_delta_step=0, max_depth=3,
                  min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,
                  nthread=None, objective='multi:softprob', random_state=0,
                  reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
                  silent=None, subsample=1, verbosity=1)



### XGBoost 모델 학습 결과 평가
- Predict 수행 후 classification_report() 결과 출력하기


```python
pred = model_xgb.predict(X_test)

print(classification_report(y_test,pred))
```

                  precision    recall  f1-score   support
    
               H       0.68      0.64      0.66        50
               L       0.79      0.67      0.72        33
               M       0.58      0.66      0.62        61
    
        accuracy                           0.65       144
       macro avg       0.68      0.65      0.67       144
    weighted avg       0.66      0.65      0.66       144


​    

## 모델 학습 결과 심층 분석


### 상관성 파악 - Logistic Regression 모델 계수



Logistic Regression 모델의 coef_ 속성을 plot하기




```python
 model_lr.coef_.shape 
```




    (3, 59)



3은 클래스이며, 59는 피쳐의 갯수입니다.


```python
model_lr.classes_
```




    array(['H', 'L', 'M'], dtype=object)




```python
fig = plt.figure(figsize=(20,10))

plt.bar(X.columns, model_lr.coef_[0, :])  #H만 출력

plt.xticks(rotation=90)

plt.show()
```


![png](학습요소_files/학습요소_86_0.png)


Regression으로 봤을 때 성적이 H인 경우, 영향을 많이 준 것은 결석일수네요.

### XGBoost 모델 변수 중요도

- feature_importances


```python
fig = plt.figure(figsize=(15, 8))

plt.bar(X.columns, model_xgb.feature_importances_)

plt.xticks(rotation=90)

plt.show()
```


![png](학습요소_files/학습요소_89_0.png)


성적 결정의 중요 요소는 결석일수와 어머니가 책임자일 경우라고 하네요.

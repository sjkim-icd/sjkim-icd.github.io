---
title:  "[머신러닝] 랜덤 포레스트"
excerpt: "랜덤포레스트의 원리, 하이퍼파라미터(n_estimators/max_features/max_depth/min_samples_leaf), 해당 알고리즘의 장단점을 다룹니다."

categories:
  - Machine-Learning
tags:
  - [machinelearning, 랜덤 포레스트, randomforest]
comments: true
toc: true
toc_sticky: true
 
date: 2021-10-09
last_modified_at: 2021-10-09

---

# 랜덤 포레스트


# [랜덤 포레스트]

## 1. 랜덤 포레스트의 개념

- 앙상블 알고리즘 중 비교적 빠른 수행 속도를 가지고 있음
- 결정 트리가 기반 알고리즘으로 결정 트리의 쉽고 직관적인 장점을 가지고 있음
- 여러 개의 결정 트리 분류기가 전체 데이터에서 배깅 방식으로 각자의 데이터를 샘플링하여 개별적으로 학습을 수행한 뒤 최종적으로 모든 분류기가 소프트 보팅을 통해 예측 결정을 함
- 개별 트리가 학습하는 데이터 세트는 전체 데이터에서 일부가 중첩되게 샘플링된 데이터 세트임, 이렇게  여러 개의 데이터 세트를 중첩되게 분리하는 것을 부트스트래핑이라고 하며 배깅 방법을 사용함
- 랜덤 포레스트의 서브셋 데이터는 부트스트래핑으로 데이터가 임의로 만들어지며, 서브세트의 데이터 건수는 전체 데이터 건수와 동일하지만 개별 데이터가 중첩되어 만들어짐, 즉 전체 데이터가 1~5로 구성되어 있는데 부트스트래핑 방법으로 서브세트를 3개로 만든다면 1번 서브셋(1,1,2,3,4), 2번 서브셋(1,2,3,4,4), 3번 서브셋(1,3,4,5,5) 등의 방식으로 만들어짐
- 이런 식으로 데이터가 중첩된 개별 데이터 셋에 대해 결정 트리를 각각 적용하는 것이 랜덤 포레스트임
- 랜덤 포레스트 알고리즘은 트리의 노드를 분할할 때 전체 특성 중에서 최선의 변수를 찾는 대신 무작위로 선택한 변수 후보 중에서 최적의 변수를 찾는 식으로 무작위성을 주입함. 이를 통해 트리를 더욱 다양하게 만들고 편향을 손해 보는 대신 분산을 낮추어 전체적으로 좋은 모델을 만듦
- 익스트림 랜덤 트리: 트리를 만들 때 각 노드는 무작위로 특성의 서브 셋을 만들어 분할에 사용함, 트리를 더욱 무작위하게 만들기 위해 최적의 임계값을 찾는 대신 후보 변수를 사용해 무작위로 분할한 다음 그 중에서 최상의 분할을 선택함, 편향이 늘어나지만 부산은 낮춤, 일반 랜덤포레스트의 경우 변수마다 가장 최적의 임곗값을 찾는 부분이 트리 알고리즘에서 가장 많이 소요되는 작업인데 이로 인해 엑스트라 트리가 더 속도가 빠름

## 2. 랜덤 포레스트의 하이퍼 파라미터

- 트리 기반의 앙상블 알고리즘은 하이퍼파라미터가 많고 튜닝 시간이 많이 소모됨, 튜닝 후 예측 성능이 크게 향상되는 경우가 많이 않음
- max_samples를 훈련 세트의 크기로 지정함

**1) n_estimators** : 결정 트리의 갯수, 디폴트는 10개

**2) max_features** : 트리를 분할하는 피처를 참조할 때 사용하는 피처 갯수, 디폴트는 auto인 sqrt임. 전체 피처가 4개면 2개를 참조

**3) max_depth, min_samples_leaf** :  결정 트리에서 과적합을 개선하기 위해 사용되는 파라미터 

## 3. 랜덤 포레스트의 장점

**1) 분산을 낮춤**

**2) 상대적 중요도를 측정하기 쉬움** : 어떤 변수를 사용한 노드가 평균적으로 불순도를 얼마나 감소시키는지 확인하여 변수 중요도를 측정하는데 가중치 평균이며, 각 노드의 가중치는 훈련 샘플 수와 같음, 훈련이 끝난 뒤 변수마다 자동으로 이 점수를 계산하고 중요도의 전체 합이 1이 되도록 결과값을 정규화함, 즉 랜덤포레스틑 변수 선택 시 어떤 변수가 중요한지 빠르게 확인이 가능함
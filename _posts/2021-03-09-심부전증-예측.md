---
layout: post
title:  "의료데이터: 심부전증 사망자 예측"
summary: "heart disease"
author: KSJ
date: '2021-03-08 09:41:00 +0900'
categories: analytics


---



### 분석 주제 : 심부전증 사망자 예측(의료데이터)

의료데이터인 심부전증 데이터를 활용하여 DATA HANDLING, EDA, MODELING을 진행해 보려고 합니다.!

 ![심부전증](/assets/brain-3017071_1920.png)

데이터의 경우, Heart Failure Prediction 데이터셋인 heart_failure_clinical_records_dataset.csv를 사용합니다.

데이터는  https://www.kaggle.com/andrewmvd/heart-failure-clinical-data 에서 다운 받을 수 있습니다.
저는 코랩에서 작업하였기 때문에 코랩에 필요한 코드로 작성하였습니다.

## Contents

1. [데이터 분석 문제 정의](#1.-데이터-분석-문제-정의)
2. [데이터 EDA](3.-데이터EDA)
3. [데이터 핸들링](#2.데이터-핸들링)
4. [모델링](#4.-모델링)
5. [마무리](#5.-마무리)
   

변수의 의미는 다음과 같습니다.<br>

```

```

​    age: 환자의 나이<br>
​    anaemia: 환자의 빈혈증 여부 (0: 정상, 1: 빈혈)<br>
​    creatinine_phosphokinase: 크레아틴키나제 검사 결과<br>
​    diabetes: 당뇨병 여부 (0: 정상, 1: 당뇨)<br>
​    ejection_fraction: 박출계수 (%)<br>
​    high_blood_pressure: 고혈압 여부 (0: 정상, 1: 고혈압)<br>
​    platelets: 혈소판 수 (kiloplatelets/mL)<br>
​    serum_creatinine: 혈중 크레아틴 레벨 (mg/dL)<br>
​    serum_sodium: 혈중 나트륨 레벨 (mEq/L)<br>
​    sex: 성별 (0: 여성, 1: 남성)<br>
​    smoking: 흡연 여부 (0: 비흡연, 1: 흡연)<br>
​    time: 관찰 기간 (일)<br>
​    DEATH_EVENT: 사망 여부 (0: 생존, 1: 사망)<br>

    ```
    
    ```

### 해당 분석에서 배울 수 있는 것
1. seaborn 데이터 시각화
2. Scikit-learn 기반의 모델링 방법(regression,xgboost)
3. Classification 모델 평가 방법(Precision-Recall 커브, ROC커브)

***
# 1. 데이터 분석 문제 정의

**target의 값은 death_event**이며, 심부전증으로 인한 사망을 예측하는 것이 해당 데이터의 분석 목적입니다.

Accuracy, Precision, 그리고 Recall 중에서도 
의료 데이터의 경우, Recall을 중요시 여깁니다.

환자라고 진단한 후 환자가 아닌 경우보다

환자가 아니라고 진단한 후 환자인 경우

더 큰 문제를 일으키므로, Recall을 중요시 여기는거죠.




# 2. 데이터 EDA

##  데이터셋 준비


```python
import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import seaborn as sns
```

Colab Notebook에 Kaggle API 세팅하기



```python
import os
```


```python
# os.environ을 이용하여 Kaggle API Username, Key 세팅하기



os.environ['KAGGLE_USERNAME']='자신의캐글유저네임'

os.environ['KAGGLE_KEY']='자신의캐글키'


```

데이터 다운로드 및 압축 해제하기



```python
# Linux 명령어로 Kaggle API를 이용하여 데이터셋 다운로드하기 (!kaggle ~)

# Linux 명령어로 압축 해제하기

!kaggle -h

!kaggle datasets download -d andrewmvd/heart-failure-clinical-data

!unzip '*.zip'
```

    usage: kaggle [-h] [-v] {competitions,c,datasets,d,kernels,k,config} ...
    
    optional arguments:
      -h, --help            show this help message and exit
      -v, --version         show program's version number and exit
    
    commands:
      {competitions,c,datasets,d,kernels,k,config}
                            Use one of:
                            competitions {list, files, download, submit, submissions, leaderboard}
                            datasets {list, files, download, create, version, init, metadata, status}
                            config {view, set, unset}
        competitions        Commands related to Kaggle competitions
        datasets            Commands related to Kaggle datasets
        kernels             Commands related to Kaggle kernels
        config              Configuration settings
    Downloading heart-failure-clinical-data.zip to /content
      0% 0.00/3.97k [00:00<?, ?B/s]
    100% 3.97k/3.97k [00:00<00:00, 1.88MB/s]
    Archive:  heart-failure-clinical-data.zip
      inflating: heart_failure_clinical_records_dataset.csv  



```python
!ls # 현재 디렉토리에 있는 모든 파일

   heart-failure-clinical-data.zip		    sample_data
    heart_failure_clinical_records_dataset.csv
```

 

#### pd.read_csv()로 csv파일 읽어들이기
```python
df = pd.read_csv('heart_failure_clinical_records_dataset.csv')
```

### 2-1. 컬럼별 EDA
DataFrame에서 제공하는 메소드를 이용하여 컬럼 분석 (head(), info(), describe())

#### df.head()
```python


df.head() 

|      |  age | anaemia | creatinine_phosphokinase | diabetes | ejection_fraction | high_blood_pressure | platelets | serum_creatinine | serum_sodium |  sex | smoking | time | DEATH_EVENT |
| ---: | ---: | :------ | -----------------------: | -------: | ----------------: | ------------------: | --------: | ---------------: | -----------: | ---: | ------: | ---: | ----------: |
|    0 |   75 | 0       |                      582 |        0 |                20 |                   1 |    265000 |              1.9 |          130 |    1 |       0 |    4 |           1 |
|    1 |   55 | 0       |                     7861 |        0 |                38 |                   0 |    263358 |              1.1 |          136 |    1 |       0 |    6 |           1 |
|    2 |   65 | 0       |                      146 |        0 |                20 |                   0 |    162000 |              1.3 |          129 |    1 |       1 |    7 |           1 |
|    3 |   50 | 1       |                      111 |        0 |                20 |                   0 |    210000 |              1.9 |          137 |    1 |       0 |    7 |           1 |
|    4 |   65 | 1       |                      160 |        1 |                20 |                   0 |    327000 |              2.7 |          116 |    0 |       0 |    8 |           1 |


```
-5로 입력할 경우, 앞의 5개, tail의 5개까지 함께 출력합니다.






#### df.info(): 데이터의 타입/non-null count
```python
df.info()
```

모든 컬럼이 non-null이며, 즉 null이 없는 상태입니다.

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 299 entries, 0 to 298
    Data columns (total 13 columns):
     #   Column                    Non-Null Count  Dtype  
    ---  ------                    --------------  -----  
     0   age                       299 non-null    float64
     1   anaemia                   299 non-null    int64  
     2   creatinine_phosphokinase  299 non-null    int64  
     3   diabetes                  299 non-null    int64  
     4   ejection_fraction         299 non-null    int64  
     5   high_blood_pressure       299 non-null    int64  
     6   platelets                 299 non-null    float64
     7   serum_creatinine          299 non-null    float64
     8   serum_sodium              299 non-null    int64  
     9   sex                       299 non-null    int64  
     10  smoking                   299 non-null    int64  
     11  time                      299 non-null    int64  
     12  DEATH_EVENT               299 non-null    int64  
    dtypes: float64(3), int64(10)
    memory usage: 30.5 KB


#### df.describe(): 수치형 데이터의 통계
```python
df.describe()
print(df.describe().to_markdown())
```
    |       |      age |    anaemia |   creatinine_phosphokinase |   diabetes |   ejection_fraction |   high_blood_pressure |   platelets |   serum_creatinine |   serum_sodium |        sex |   smoking |     time |   DEATH_EVENT |
    |:------|---------:|-----------:|---------------------------:|-----------:|--------------------:|----------------------:|------------:|-------------------:|---------------:|-----------:|----------:|---------:|--------------:|
    | count | 299      | 299        |                    299     | 299        |            299      |            299        |       299   |          299       |      299       | 299        | 299       | 299      |     299       |
    | mean  |  60.8339 |   0.431438 |                    581.839 |   0.41806  |             38.0836 |              0.351171 |    263358   |            1.39388 |      136.625   |   0.648829 |   0.32107 | 130.261  |       0.32107 |
    | std   |  11.8948 |   0.496107 |                    970.288 |   0.494067 |             11.8348 |              0.478136 |     97804.2 |            1.03451 |        4.41248 |   0.478136 |   0.46767 |  77.6142 |       0.46767 |
    | min   |  40      |   0        |                     23     |   0        |             14      |              0        |     25100   |            0.5     |      113       |   0        |   0       |   4      |       0       |
    | 25%   |  51      |   0        |                    116.5   |   0        |             30      |              0        |    212500   |            0.9     |      134       |   0        |   0       |  73      |       0       |
    | 50%   |  60      |   0        |                    250     |   0        |             38      |              0        |    262000   |            1.1     |      137       |   1        |   0       | 115      |       0       |
    | 75%   |  70      |   1        |                    582     |   1        |             45      |              1        |    303500   |            1.4     |      140       |   1        |   1       | 203      |       1       |
    | max   |  95      |   1        |                   7861     |   1        |             80      |              1        |    850000   |            9.4     |      148       |   1        |   1       | 285      |       1       |

이 describe에서 알 수 있는 것은 다음과 같습니다.

1) 0과 1로 이뤄진 변수의 mean을 보면 imbalance 상태를 알아볼 수 있습니다.

2) max min이 과도한지 않은가/증가세가 일정한가를 통해 outlier 등을 파악할 수 있습니다.2-2. 수치형 데이터 EDA

### 2-2. 수치형 데이터 EDA


```python
df.columns
```
    Index(['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',
           'ejection_fraction', 'high_blood_pressure', 'platelets',
           'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time',
           'DEATH_EVENT'],
          dtype='object')

#### seaborn의 histplot, jointplot, pairplot
수치형 데이터의 EDA는 seaborn의 histplot, jointplot을 통해 진행할 수 있습니다.

#### sns.histplot
- AGE
```python
sns.histplot(x='age',data=df, hue='DEATH_EVENT', kde =True)
```
![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_21_1.png)
histplot을 살펴보면 롱테일의 구조를 가지고 있습니다.

hisplot의 hue는 강력한데요. hue에 따라 여러개의 히스토그램으로 쪼개져서 표현되고 겹치는 부분은 회색으로 표현되네요.

사망한 사람은 나이대가 고루게 분포하고 사망하지 않은 사람은 젊은 쪽으로 몰려있음을 알 수 있습니다.


- creatinine_phosphokinase  <br>

```python
sns.histplot(x='creatinine_phosphokinase',data=df)
```

![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_22_1.png)
먼저, 그래프를 그려보고 outlier가 많은 경우 특정 값 이하만 추출하여 다시 그래프를 그렸습니다.


```python
sns.histplot(data =df.loc[df['creatinine_phosphokinase'] <3000,'creatinine_phosphokinase'])
```

![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_23_1.png)

해당 그래프에서는 딱히 통계적인 특성이 드러나지는 않네요.

- ejection_fraction <br>


```python

#sns.histplot(data = df, x='ejection_fraction') # 중간에 빈 경우는 bins 다시 조정

sns.histplot(data = df, x='ejection_fraction',bins = 13,hue = 'DEATH_EVENT' ,kde =True )

```

![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_24_1.png)

histogram 중간에 비는 경우, bins가 좁아 그런 경우도 있으니, bins를 다시 조정해봅니다.
‘ejection_fraction’이 낮은 사람이 사망을 많이 하는 경향을 볼 수 있습니다.

- platelets 혈소판
```python
sns.histplot(data = df, x='platelets',bins = 13,hue = 'DEATH_EVENT' ,kde =True )
```


![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_25_1.png)

혈소판의 경우, 전체 히스토그램은 통계적으로 보이는데,

death이벤트와 상관성은 보이지 않는 듯 합니다.

#### joint plot :히스토그램,KDE플랏, SCATTER 플랏
```python

sns.jointplot(x='platelets',y='creatinine_phosphokinase',hue = 'DEATH_EVENT',data=df, alpha = 0.3)

```
스캐터플랏이 뭉쳐서 판단 어려울때 알파값을 조절하여

투명도를 조정합니다. 대부분의 점들이 뭉쳐있어

판단을 내리기는 힘들어 보입니다.



![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_26_1.png)


### 2-3. 범주형 데이터 EDA
#### Boxplot
범주형은 박스플롯 계열의 boxplot(), violinplot(), swarmplot()을 사용합니다.
hue 키워드를 사용하여 범주 세분화가 가능합니다.
```python
sns.boxplot(x='DEATH_EVENT',y='ejection_fraction',data=df)


```


![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_30_1.png)

박스플랏으로 통계치를 한 눈에 보고, 아웃라이어도 볼 수 있습니다.

박스플랏의 경우, 간단하지만 여러 정보가 담겨있어 경영층과 대화할 때 많이 쓰곤합니다.

```python
sns.boxplot(x='smoking',y='ejection_fraction',data=df)

# 흡연자의 ejection_fraction이 좁음
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7feef976f510>




![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_31_1.png)

- sns.violinplot
violinplot은 박스플롯의 변형으로 박스플랏 + 히스토그램 정보 + 아웃라이어의 정보를 담고 있습니다.

```python
sns.violinplot(x='DEATH_EVENT',y='ejection_fraction',data=df,hue='smoking')
```


![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_32_1.png)


- swarmplot <br>
swarmplot은 스캐터 , 바이올린 플랏을 합친 것으로 볼 수 있는데요. 대신 박스플랏의 통계정보는 표시되지 않습니다.
```python
sns.swarmplot(x='DEATH_EVENT',y='ejection_fraction',data=df,hue='smoking')
```


    <matplotlib.axes._subplots.AxesSubplot at 0x7fef02249110>
![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_33_2.png)





# 3. 데이터 전처리 
### 모델 학습을 위한 데이터 전처리

#### StandardScaler를 이용하여 데이터 전처리하기 <br>

```python
from sklearn.preprocessing import StandardScaler
```

수치형 입력 데이터, 범주형 입력 데이터, 출력 데이터로 구분하기 <br>

```python
X_num = df[['age', 'creatinine_phosphokinase','ejection_fraction', 'platelets','serum_creatinine', 'serum_sodium', 'time']]

X_cat = df[['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']]

y = df['DEATH_EVENT']
```

수치형 입력 데이터를 전처리하고 입력 데이터 통합하기 <br>
```python
scaler = StandardScaler()
scaler.fit(X_num)
X_scaled = scaler.transform(X_num) #numpy 형태
X_scaled = pd.DataFrame(data=X_scaled, index=X_num.index, columns=X_num.columns)
X = pd.concat([X_scaled, X_cat], axis=1) #합쳐주기, axis=1 넣어야 컬럼을 붙임
```

```python
X_num.columns

 Index(['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets',
           'serum_creatinine', 'serum_sodium'],
          dtype='object')

```


#### 학습데이터와 테스트데이터 분리하기


```python
from sklearn.model_selection import train_test_split
```

train_test_split() 함수로 학습 데이터와 테스트 데이터 분리하기 <br>

```python
X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.3, random_state=42 )

```
train_test_split() 함수는 셔플도 가능, 디폴트는 T/random_state = random seed



# 4. 모델 학습 및 평가


####  Logistic Regression 모델 생성/학습하기



```python
from sklearn.linear_model import LogisticRegression
```

LogisticRegression 모델 생성/학습
```python
model_lr = LogisticRegression(max_iter=1000)
model_lr.fit(X_train, y_train)


    LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                       intercept_scaling=1, l1_ratio=None, max_iter=1000,
                       multi_class='auto', n_jobs=None, penalty='l2',
                       random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                       warm_start=False)

```
verbose =1로 하면 학습과정을 보여줌





```python
from sklearn.metrics import classification_report
```

####  Logistic Regression  Predict를 수행하고 classification_report() 결과 출력하기
```python
pred = model_lr.predict(X_test)

print(classification_report(y_test, pred))


                  precision    recall  f1-score   support
    
               0       0.76      0.94      0.84        53
               1       0.88      0.57      0.69        37
    
        accuracy                           0.79        90
       macro avg       0.82      0.76      0.76        90
    weighted avg       0.81      0.79      0.78        90

```


​    

#### XGBoost 모델 생성/학습하기



```python
from xgboost import XGBClassifier
```

```python
model_xgb = XGBClassifier()

model_xgb.fit(X_train, y_train)


    XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
                  colsample_bynode=1, colsample_bytree=1, gamma=0,
                  learning_rate=0.1, max_delta_step=0, max_depth=3,
                  min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,
                  nthread=None, objective='binary:logistic', random_state=0,
                  reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
                  silent=None, subsample=1, verbosity=1)

```


#### XGBClassifier  모델 학습 결과 평가하기



```python
# Predict를 수행하고 classification_report() 결과 출력하기

pred = model_xgb.predict(X_test)

print(classification_report(y_test, pred))

               precision    recall  f1-score   support
    
               0       0.73      0.89      0.80        53
               1       0.77      0.54      0.63        37
    
        accuracy                           0.74        90
       macro avg       0.75      0.71      0.72        90
    weighted avg       0.75      0.74      0.73        90

```


​    

#### 변수 중요도 확인하기


XGBClassifier 모델의 feature_importances_를 이용하여 중요도 plot 확인

```python
plt.bar(X.columns, model_xgb.feature_importances_) #x축, y축

plt.xticks(rotation=90) #x축 글자 90도 로테이션

plt.show() #그래프만 나오게

```

![png](assets/kaggle/심부전증/Chapter_01_심부전증_완강_60_0.png)

time이 가장 중요한 변수로 나오는데 time 관련하여 histplot을 그려봅니다.

```python
X.columns

 Index(['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets',
           'serum_creatinine', 'serum_sodium', 'anaemia', 'diabetes',
           'high_blood_pressure', 'sex', 'smoking'],
          dtype='object')
```

```python
sns.histplot(x='time',data=df,hue='DEATH_EVENT',kde=True)
```

![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_62_1.png)

사망자의 경우, 관찰초기에 사망해서 점점 낮아지는 감마의 형태를 보이는데요. 
생존자는 쌍봉형태로 나타납니다.
사망결과를 보았기 때문에 타임에 사망결과가 이미 녹아 들어갔다고 볼 수 있습니다. 
이런 경우를 데이터 리퀴즈라고 하는데요.
타임에는 이미 death_event가 들어가 있으므로 해당 변수를 제외하고 다시 모델링을 진행합니다.

#### TIME 변수 제외 후 모델링
```python
X_num = df[['age', 'creatinine_phosphokinase','ejection_fraction', 'platelets','serum_creatinine', 'serum_sodium']]
X_cat = df[['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']]
y = df['DEATH_EVENT']
scaler = StandardScaler()
scaler.fit(X_num)
X_scaled = scaler.transform(X_num) 
X_scaled = pd.DataFrame(data=X_scaled, index=X_num.index, columns=X_num.columns)
X = pd.concat([X_scaled, X_cat], axis=1) 


# train_test_split() 함수로 학습 데이터와 테스트 데이터 분리하기
X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.3, random_state=42 )
X_train

# LogisticRegression 모델 생성/학습
model_lr = LogisticRegression(max_iter=1000)
model_lr.fit(X_train, y_train)


# Predict를 수행하고 classification_report() 결과 출력하기
pred = model_lr.predict(X_test)
print(classification_report(y_test, pred))

              precision    recall  f1-score   support
    
               0       0.67      0.91      0.77        53
               1       0.72      0.35      0.47        37
    
        accuracy                           0.68        90
       macro avg       0.69      0.63      0.62        90
    weighted avg       0.69      0.68      0.65        90


```

​    

```python
# XGBClassifier 모델 생성/학습
model_xgb = XGBClassifier()
model_xgb.fit(X_train, y_train)

# Predict를 수행하고 classification_report() 결과 출력하기
pred = model_xgb.predict(X_test)
print(classification_report(y_test, pred))

          precision    recall  f1-score   support
    
               0       0.70      0.87      0.77        53
               1       0.71      0.46      0.56        37
    
        accuracy                           0.70        90
       macro avg       0.70      0.66      0.67        90
    weighted avg       0.70      0.70      0.68        90
```


​    

#### XGBClassifier 모델의 feature_importances_를 이용하여 중요도 plot

```python

plt.bar(X.columns, model_xgb.feature_importances_) #x축, y축
plt.xticks(rotation=90) 
plt.show() 
```


![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_65_0.png)
serum_creatinine/ejection_fraction이 가장 중요한 변수로 나오므로
두 변수에 대한 조인트 플랏을 진행해봅니다.

#### 중요한 두 변수에 대한 조인트 플랏
```python
sns.jointplot(x='ejection_fraction',y = 'serum_creatinine',data=df, hue = 'DEATH_EVENT')
```

![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_66_1.png)
조인트 플랏에서 사망여부의 점들이 상당히 잘 구분됨을 볼 수 있습니다.

#### Precision-Recall 커브 확인

```python
from sklearn.metrics import plot_precision_recall_curve
```

#### 두 모델의 Precision-Recall 커브를 한번에 그리기 
```python
fig = plt.figure() #캔버스
ax = fig.gca() #현재 x를 받아둠
plot_precision_recall_curve(model_lr, X_test, y_test, ax=ax) #리그레션
plot_precision_recall_curve(model_xgb, X_test, y_test, ax=ax) #xgb
```

![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_70_1.png)
해당 모델의 경우, 리그레션 모델이 xgb보다 일반적으로 좋은 성능을 가지고 있음을 알 수 있습니다.

#### ROC 커브 확인하기


```python
from sklearn.metrics import plot_roc_curve
```

#### 두 모델의 ROC 커브를 한번에 그리기 

```python
fig = plt.figure()
ax = fig.gca()
plot_roc_curve(model_lr, X_test, y_test, ax=ax)
plot_roc_curve(model_xgb, X_test, y_test, ax=ax)
```

![png](/assets/kaggle/심부전증/Chapter_01_심부전증_완강_73_1.png)
해당 모델의 경우, false positive rate를 낮게 유지해야 하는데요. 
auc의 경우에는 xgb가 더 좋게 나옴을 알 수 있습니다.



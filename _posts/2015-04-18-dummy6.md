---
layout: post
title:  "modeling process"
date:   2021-03-29T14:25:52-05:00
author: KSJ
categories: modeling
tags: lorem ipsum
---

1. 모델 개발 방법
- 신용쪽에서 주로 사용했던 모델링 기법
0) 분석데이터 설계
타겟이 적은 경우, 기준월을 1개월씩 이동하며 데이터를 적재하는 window sliding 방식 적용
1) 타겟 Y와 관련있을 후보 변수 수집
2) 간단 10/100분위 변수로 구간화하여 WOE,IV를 통한 Y값과의 관계 파악 후 변수 제거
3) 변수 선택 후 Grouping/그룹핑 후 시계열 및 WOE분석하여 안정적인 변수 
- 변수 구간화 의미
연속형 변수를 범주형이나 순위형 변수로 변환하는 처리
- 변수 구간화를 사용하는 이유
(1) 이상치로 인한 문제 완화를 통해 안정성 확보
이상치가 포함된 경우, 이상 현상을 학습시킬 필요는 없으므로 보통 이상치를 제거
구간화를 하면 평균을 이용한 대푯값보다 구간화를 통한 분포가 집단의 데이터를 더 잘 설명함
(2) 결측치 처리 용이
결측치를 다루는 방법은 여러가지가 있는데 데이터/비즈니스의 특성에 따라 핸들링방법이 다름
최빈값, 평균값 등으로 채워넣는다고 했을때 그 값에 대한 타당성과 근거가 명확하지 않으면
쓰기 어려울 수 있음

구간화를 하면 결측의 경우, 결측/알수없음 등으로 할당이 가능하여
결측인 집단의 특성을 파악할 수 있음
(3) 과적합 완화
(4) 결과 해석이 용이
(5) 변수의 시계열에 대한 안정성을 높여줌

- 구간화 방법
(1) WOE가 높은 값에서 낮은 값으로 적용
(2) 업무/비즈니스적으로 의미있는 커트라인 적용
(3) GROUP 갯수가 10개가 넘지 않도록 조정
(4) GROUP에 속한 데이터 갯수가 너무 적지 않도록 구성
(5) NULL 값은 0처리 하거나 높은 CATEGORY에 속하도록 할당
(6) 변수값이 효과적으로 구간화되었는지는 WOE와 IV를 통해 추정
(7) 속성 순서별 WOE가 역전되는 경우가 있으면 묶어주기, 또는 추세선을 그려  Y에 대한 비율이 변경되는 경우 묶어주기-> woe와 iv를 뽑아 엑셀로 하거나 또는 추세선에서 변화가 생길 경우 범위로 지정하는 코드를 짤 수도 

4) 변수선택: IV(Information Value)
(1) 우량집단과 불량집단 간의 구성비를 이용하여 IV값 산출
(2) 라벨 1에서 피쳐 1이 발생할 확률이 라벨 0에서 피쳐 1이 발생할 확률의 상대적인 크기
(3) IV란 각 설명변수가 타겟변수를 설명하는데 어떤 pattern과 power를 가지고 있는지 알아보는데 쓰이는 지표로 information value의 값이 클수록 타겟변수에 대한 예측력이 높다는 것을 의미한다.
(4) 모델에서 변수의 사용유무를 판단하는 feature selection에 사용
(5) 주로 모델 학습전 첫 단계에서 변수 제거에 사용
(6) IV와 WOE는 로지스틱 회귀와 밀접한 관계
WOE는 good과 bad 분포를 활용, 데이터가 good으로 쏠린 경우, WOE는 무조건 잘 나올 수 밖에 없고 이에 따라 IV도 잘 나옴. (IV는 WOE를 활용함)
따라서 IV의 값을 볼 때는 데이터의 분포를 먼저 살펴보는 것이 중요하다.

WOE(Weight of Evidence) = ln(%NON-EVENT/%EVENT)
변수의 Binning이 적절한지 나타내는 지표로 Binning 구간별 WOE가 단조증가, 단조감소하는 형태로 Binning 수행
IV(Information Value) = (%NON-EVENT/%EVENT) * ln(%NON-EVENT/%EVENT)
변수의 WOE를 통해 산출하며, 값이 클수록 예측력이 높고, 설명변수의 상대적 영향력을 평가하는 지표로 활용
- %EVENT: (범주별 EVENT 관측치수/전체 EVENT 관측치수) * 100
- %NON-EVENT: (범주별 NON EVENT 관측치수/전체 EVENT 관측치수) * 100
- Odds: (범주별 NON EVENT 관측치수/전체 EVENT 관측치수)

IV 값 의미
0~0.02: 무의미
0.02~0.1: 낮은 예측력
0.1~0.3:중간 예측력
0.3~0.5: 강한 예측력
0.5~1:너무 강한 예측력으로 의심이 필요

5) 결측값
- 분포 유사성을 보고 할당 ex) nice결측 5와 분포가 유사하여 할당
- 성향의 유사함: 온라인,모바일,PC의 성향이 유사한 경우 묶기

6) samlpling(절대타겟값부족 및 불균형데이터) 및 modeling
(1) 절대 타겟값 부족
윈도우 슬라이딩 방식으로 타겟값 확보
- 계절성을 고려하기 위해 1년에 대해 타겟비율은 유지한 채로 층화추출로 가지고올 수도 있으며
- 월별 sampling을 할때 타겟값:넌타겟값=1:1로 뽑는 경우가 
(2) 불균형 데이터
불균형 데이터

데이터가 불균형한 경우, 
분포가 높은 클래스에 모델이 가중치를 많이 두기 때문에Accuracy는 높지만 분포가  Precision은 낮을 수 있고, 분포가 작은 클래스의 재현율이 낮아질 수 있음

데이터 불균형 해결 방법
(1) undersampling/down sampling
- 데이터 분포가 높은 값을 낮은 값의 크기로 맞춰주는 것
정보가 유실되는 문제가 있을 수 있음
- Random Under Sampling
- Tomek link
- CNN(Condensed Nearest Neighbour)
- Edited Nearest Neighbours

(2) over sampling/up sampling
분포가 작은 클래스의 값을 큰 클래스로 맞춰주는 것
정보의 유실은 막지만 , 여러 유형의 관측치를 추가하여 오버피팅 가능성이 있음
Random Over Sampling
ADASYN(Adaptive Synthetic Sampling) 
SMOTE

(3) combine sampling(오버+언더)
 SMOTE + ENN
 SMOTE + TOMEK


샘플링에 대한 종류가 많이 나옴
https://shinminyong.tistory.com/34


7) 모델검증 및 성능 확인
 검증용 데이터와 테스트데이터 적용
(1) 오버피팅
- 개발 데이터에 비해 검증데이터의 성능이 과도하게 높은 경우
(2) 성능지표
- 비중/타겟0/타겟1/회원수/분포/R/CR/LIFT/누적회원수/누적TARGET/누적R/누적CR/누적LIFT
- 분포: 해당구간의 회원수/전체회원수
- R: 해당구간의 타겟1회원수/해당구간의 회원수(검출효율 response rate : 모델 예측 고객 중 실제 반응고객 비율)
- CR: 해당구간의 타겟1회원수/타겟1 전체회원수(검출력captured responsed rate:실제 반응고객 중 모델 예측 반응고객 비율)
- LIFT: R/(타겟1 전체회원수/전체회원수) (model을 적용햇을 경우, 적용하지 않았을 경우 대비 향상도)
- KS통계량(kolmogorov-smirnov statistics) targer과 non target의 누적분포 차이로 산출되며, 모델 성능(변별력)을 평가하기 위한 지표
0.2: 미니멈
0.3이상: 굿
0.4이상 very good
0.5이상 excellent
- Gini index: 누적 target비율과 누적 non target 비율의 분포도를 이용해 산출되며 모델 성능(변별력) 평가하기 위한 지표
0.25:미니멈
0.35이상: good
0.5이상: very good
0.6이상: excellent



9. 모델 모니터링 관련 주요 지표
PSI(population stability index)
모델 개발시점과 검증 시점 간 스코어별 분포의 안정성을 검증하기 위한 지표
SEI(Score effectiveness index)
두 시점간 모델 예측력의 안정성 및 효율성 검증 지표
PSI, SEI값이 클수록 개발시점과 검증 시점 간 분포차이가 크며 모델이 안정적이지 못함
0~10: 개발당시와 비교해 변화조짐없음
10~30: 변화조짐보임(변화요인분석)
30~50: 변화발생(재개발필요)
50~: 현저한 변화발생(재개발필요)

https://m.blog.naver.com/gksshdk8003/221517070898
